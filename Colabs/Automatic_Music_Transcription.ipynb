{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["JBHlyL3hpzaa"],"authorship_tag":"ABX9TyMqHZMSsJFYxUFvRAN1npPF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"yqQ9biwvldU3","executionInfo":{"status":"ok","timestamp":1678626520873,"user_tz":-60,"elapsed":57868,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"outputs":[],"source":["%%capture\n","\n","#@markdown Installing libs & files\n","!pip install mido\n","!pip install pretty_midi\n","!pip install mir_eval\n","!pip install note_seq==0.0.3\n","!pip install midi2audio\n","# !pip install gdown==4.2.0\n","!pip install --upgrade --no-cache-dir gdown\n","!wget https://musical-artifacts.com/artifacts/387/KBH_Real_and_Swell_Choir.sf2\n","!sudo apt-get install fluidsynth\n","\n","''"]},{"cell_type":"code","source":["#@markdown install models\n","\n","\n","import gdown\n","url = \"https://drive.google.com/file/d/1zjfrtq7-N8YKK2WE5iEfH-FpFghyUbir/view?usp=sharing\"\n","gdown.download(url=url,  output=\"PIANO_MODELS.zip\", fuzzy=True)\n","\n","!unzip PIANO_MODELS.zip"],"metadata":{"cellView":"form","id":"SG46CDXMAVCl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Setup"],"metadata":{"id":"JBHlyL3hpzaa"}},{"cell_type":"code","source":["#@markdown Imports & Constants\n","\n","import os\n","os.environ[\"KMP_SETTINGS\"] = \"false\"\n","\n","RNNTransformer_params = [\n","                      'embed_dim_',\n","                      'num_heads_',\n","                      'feed_forward_dim_',\n","                      'num_layers_enc_',\n","                      'key_dim_',\n","                      'HOP_LENGTH_', \n","                      'auc_',\n","                      'ONLY_ONSET_',\n","                      'lstmU_',\n","                      ]\n","\n","from math import *\n","import ipywidgets as widgets\n","from IPython.display import display\n","from google.colab import files\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","print(tf.config.get_visible_devices())\n","from numpy.linalg import norm\n","import os\n","import gdown\n","import zipfile\n","import pickle\n","import os.path\n","from google.colab import files\n","from datetime import datetime\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pathlib\n","import librosa\n","from torch.nn.utils import clip_grad_norm_\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm import tqdm\n","import time\n","from librosa.filters import mel as mel_filter\n","from librosa.util import pad_center\n","from scipy.signal import get_window\n","import json\n","from abc import abstractmethod\n","from glob import glob\n","import soundfile\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","# from tqdm.notebook import tqdm\n","import multiprocessing\n","import sys\n","import mido\n","import time\n","import pretty_midi\n","import collections\n","from mir_eval.util import hz_to_midi\n","import mir_eval\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.utils import to_categorical\n","from math import floor as floor_\n","from mir_eval.onset import evaluate as FPR_onset\n","from librosa import note_to_midi as N2M\n","from librosa import midi_to_note as M2N\n","import itertools\n","from midi2audio import FluidSynth\n","import note_seq\n","from note_seq import sequences_lib\n","from note_seq import constants\n","from note_seq import midi_io\n","from note_seq.midi_io import  note_sequence_to_midi_file, midi_to_note_sequence\n","from mido import Message, MidiFile, MidiTrack\n","from mir_eval.util import hz_to_midi, midi_to_hz\n","from math import ceil\n","from mir_eval.transcription import precision_recall_f1_overlap as FPR_tran\n","from mir_eval.onset import evaluate as FPR_onset\n","from midi2audio import FluidSynth\n","from IPython.display import Audio as PlayAudio\n","from IPython import display\n","import base64\n","import io\n","from scipy.io import wavfile\n","import pickle\n","from google.colab import output as output_\n","from note_seq import sequences_lib\n","from note_seq import constants\n","from note_seq.midi_io import  note_sequence_to_midi_file\n","from mido import Message, MidiFile, MidiTrack\n","from mir_eval.util import hz_to_midi\n","\n","SAMPLE_RATE = 16000\n","MIN_MIDI = 21\n","MAX_MIDI = 108\n","MEL_FMIN = 30\n","WINDOW_LENGTH = 2048\n","HOP_LENGTH=512\n","ONLY_ONSET=False\n","ONLY_FRAME=False\n","CNNdeeper=False\n","Transformer_Model=False\n","EncoderLstm_Model = False\n","fs_path='KBH_Real_and_Swell_Choir.sf2'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"mOq7hrqsmzq9","executionInfo":{"status":"ok","timestamp":1678630316462,"user_tz":-60,"elapsed":247,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}},"outputId":"fd486e9c-7c36-4d6c-9580-cd8c87ba0024"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"]}]},{"cell_type":"code","source":["#@markdown utils\n","\n","\n","\n","def plot_sequences_midis_threhsold(MIDIs, threhsold_str='_0.4_'):\n","    for midi_ in MIDIs:\n","        if threhsold_str in midi_:\n","            print(midi_)\n","            sequence = note_seq.midi_file_to_note_sequence(midi_)\n","            note_seq.plot_sequence(sequence, )\n","\n","def sinusoidal(shape, dtype = np.float32, min_scale: float = 1.0,\n","               max_scale: float = 10000.0,):\n","    '''\n","    sinusoidal positional embedding\n","    '''    \n","    if len(list(shape)) != 2:\n","        raise ValueError(\n","            f'Expected a 2D shape (max_len, features), but got {shape}.')\n","    max_len, features = shape\n","    output = np.zeros((max_len, features), dtype=dtype)\n","    position = np.arange(0, max_len)[:, np.newaxis]\n","    scale_factor = -np.log(max_scale / min_scale) / (features // 2 - 1)\n","    div_term = min_scale * np.exp(np.arange(0, features // 2) * scale_factor)\n","    output[:, :features // 2] = np.sin(position * div_term)\n","    output[:, features // 2:2 * (features // 2)] = np.cos(position * div_term)\n","    return output\n","\n","\n","def save_midi(path, pitches, intervals, velocities=None):\n","    '''\n","    save midi data as piano midi\n","    intervals: list -> each item[start_time, end_time]\n","    pitches: list(int)\n","    '''\n","    file = pretty_midi.PrettyMIDI()\n","    piano = pretty_midi.Instrument(program=0)\n","    for i, pitch in enumerate(pitches):\n","        interval=intervals[i]\n","        if velocities!=None:\n","            velocity = velocities[i]\n","        else:\n","            velocity=100\n","        note = pretty_midi.Note(velocity=velocity, pitch=pitch, start=interval[0], end=interval[1])\n","        piano.notes.append(note)\n","\n","\n","    file.instruments.append(piano)\n","    file.write(path)\n","\n","def midi2wav(midi_path, wav_path, fs_path=fs_path, sr=16000):\n","    fs = FluidSynth(fs_path, sample_rate=sr)\n","    fs.midi_to_audio(midi_path, wav_path)\n","\n","\n","_play_count = 0 \n","def play_audio(audio_path, #array_of_floats,\n","         sample_rate=SAMPLE_RATE,\n","         ephemeral=True,\n","         autoplay=False,\n","         offset=10,\n","         duration=15):\n","  # DDSP play audio on google colab\n","  # https://github.com/magenta/ddsp/blob/main/ddsp/colab/colab_utils.py\n","  \"\"\"Creates an HTML5 audio widget to play a sound in Colab.\n","  This function should only be called from a Colab notebook.\n","  Args:\n","    array_of_floats: A 1D or 2D array-like container of float sound samples.\n","      Values outside of the range [-1, 1] will be clipped.\n","    sample_rate: Sample rate in samples per second.\n","    ephemeral: If set to True, the widget will be ephemeral, and disappear on\n","      reload (and it won't be counted against realtime document size).\n","    autoplay: If True, automatically start playing the sound when the widget is\n","      rendered.\n","  \"\"\"\n","  # If batched, take first element.\n","  array_of_floats, sr = librosa.load(audio_path, sr=sample_rate, duration=duration, offset=offset)\n","  if len(array_of_floats.shape) == 2:\n","    array_of_floats = array_of_floats[0]\n","\n","  normalizer = float(np.iinfo(np.int16).max)\n","  array_of_ints = np.array(\n","      np.asarray(array_of_floats) * normalizer, dtype=np.int16)\n","  memfile = io.BytesIO()\n","  wavfile.write(memfile, sample_rate, array_of_ints)\n","  html = \"\"\"<audio controls {autoplay}>\n","              <source controls src=\"data:audio/wav;base64,{base64_wavfile}\"\n","              type=\"audio/wav\" />\n","              Your browser does not support the audio element.\n","            </audio>\"\"\"\n","  html = html.format(\n","      autoplay='autoplay' if autoplay else '',\n","      base64_wavfile=base64.b64encode(memfile.getvalue()).decode('ascii'))\n","  memfile.close()\n","  global _play_count\n","  _play_count += 1\n","  if ephemeral:\n","    element = 'id_%s' % _play_count\n","    display.display(display.HTML('<div id=\"%s\"> </div>' % element))\n","    js = output_._js_builder  # pylint:disable=protected-access\n","    js.Js('document', mode=js.EVAL).getElementById(element).innerHTML = html\n","  else:\n","    display.display(display.HTML(html))\n","\n"],"metadata":{"cellView":"form","id":"LYcNzRBZn3yP","executionInfo":{"status":"ok","timestamp":1678630390085,"user_tz":-60,"elapsed":330,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["#@markdown Mel spectrogram\n","\n","def get_forward_basis(filter_length=2048, window='hann'):\n","\n","    win_length = filter_length\n","    # window='hann' # blackmanharris hann\n","    fourier_basis = np.fft.fft(np.eye(filter_length))\n","\n","    cutoff = int((filter_length / 2 + 1))\n","    fourier_basis = np.vstack([np.real(fourier_basis[:cutoff, :]),\n","                                np.imag(fourier_basis[:cutoff, :])])\n","\n","    forward_basis = fourier_basis[:, None, :]\n","    forward_basis_c = forward_basis.copy()\n","\n","    fft_window = get_window(window, win_length, fftbins=True, )\n","    fft_window = pad_center(fft_window, filter_length)\n","    forward_basis *= fft_window\n","    forward_basis = forward_basis.T.astype(np.float32)\n","    forward_basis = np.expand_dims(forward_basis, 0)\n","    forward_basis = tf.convert_to_tensor(forward_basis)\n","\n","    return forward_basis\n","\n","def get_mel_filter(sample_rate=16000, filter_length=2048, n_mels=229, mel_fmin=30, mel_fmax=8000, htk=True):\n","\n","    mel_basis =  mel_filter(sample_rate, filter_length, n_mels, mel_fmin, mel_fmax, htk=htk)\n","    mel_basis = tf.convert_to_tensor(mel_basis)\n","\n","    return mel_basis\n","\n","class mel_tf(tf.keras.Model):\n","        \n","    def __init__(self,\n","                 filters,\n","                 mel_basis,\n","                 hop_size=512,\n","                 return_spec=False):\n","        super(mel_tf, self).__init__()\n","        self.filters = filters\n","        self.mel_basis = mel_basis\n","        self.hop_size = hop_size\n","        self.Dim1 =  filters.shape[1]\n","        self.Dim3 =  filters.shape[3]\n","        self.return_spec=return_spec\n","    def call(self, input_data):\n","        num_batches = input_data.shape[0]\n","        num_samples = input_data.shape[1]\n","        dim2 = int(num_samples/self.hop_size) + 1\n","        input_data = tf.pad(input_data, ([0, 0], [int(self.Dim1  / 2), int(self.Dim1  / 2)]), mode='REFLECT')\n","        input_data = tf.expand_dims(input_data, -1)\n","        input_data = tf.expand_dims(input_data, 1)\n","        forward_transform = tf.nn.conv2d(input_data, self.filters, self.hop_size, 'VALID')\n","        forward_transform = tf.squeeze(forward_transform)\n","        if num_batches > 1 :\n","            forward_transform = tf.transpose(forward_transform, perm=[0, 2, 1])\n","        else :\n","            forward_transform = tf.transpose(forward_transform)\n","            forward_transform = tf.reshape(forward_transform, [num_batches, self.Dim3, dim2])\n","        real_part = forward_transform[:, :int(self.Dim1  / 2 + 1), :]\n","        imag_part = forward_transform[:, int(self.Dim1  / 2 + 1):, :]\n","        magnitude = tf.math.sqrt(real_part**2 + imag_part**2)\n","        if self.return_spec:\n","            log_spec = tf.math.log(tf.clip_by_value(magnitude, clip_value_min =1e-5 , clip_value_max=np.inf))\n","            return log_spec\n","        else:\n","            mel_output = tf.matmul(self.mel_basis, magnitude)\n","            mel_output = tf.math.log(tf.clip_by_value(mel_output, clip_value_min =1e-5 , clip_value_max=np.inf))\n","            return mel_output\n","\n"],"metadata":{"cellView":"form","id":"_qqA0iePnA6t","executionInfo":{"status":"ok","timestamp":1678629899537,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"mTkgDpzuOKLc","cellView":"form","executionInfo":{"status":"ok","timestamp":1678629899537,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"outputs":[],"source":["#@markdown Mt3_Encoder_Layer\n","\n","class Mt3_Encoder_Layer(keras.layers.Layer):\n","    def __init__(self, embed_dim=512, num_heads=6,\n","                 feed_forward_dim=2048, key_dim=64,\n","                 rate=0.1):\n","        super().__init__()\n","\n","        self.pre_attention_layer_norm = layers.LayerNormalization(epsilon=1e-6, name='pre_attention_layer_norm', scale=False)\n","\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=key_dim,  use_bias=False, name='attention'\n","        )\n","\n","        self.pre_mlp_layer_norm = layers.LayerNormalization(epsilon=1e-6, name='pre_mlp_layer_norm', scale=False)\n","\n","        self.mlp = keras.Sequential(\n","                    [\n","                        layers.Dense(feed_forward_dim, use_bias=False),#, activation='relu'\n","                        layers.Dense(embed_dim, use_bias=False),\n","                    ]\n","                )\n","    def set_norm_attention_norm_weights(self, weights):\n","        self.pre_attention_layer_norm.set_weights([weights[0]])\n","        self.attention.set_weights(weights[1:-1])\n","        self.pre_mlp_layer_norm.set_weights([weights[-1]])\n","\n","    def freeze_norm_attention_norm(self):\n","        self.pre_attention_layer_norm.trainable=False\n","        self.attention.trainable=False\n","        self.pre_mlp_layer_norm.trainable=False\n","\n","    def set_norm_attention_norm_trainable(self):\n","        self.pre_attention_layer_norm.trainable=True\n","        self.attention.trainable=True\n","        self.pre_mlp_layer_norm.trainable=True\n","\n","    def call(self, input):\n","\n","        x = self.pre_attention_layer_norm(input)\n","        x = self.attention(x, x)\n","        x = x + input\n","        y = self.pre_mlp_layer_norm(x)\n","        y = self.mlp(y)\n","        y= y + x\n","\n","        return y\n","\n","\n","#@markdown Mt3_Encoder\n","\n","class Mt3_Encoder(tf.keras.Model):\n","    def __init__(self, n_frames=200, embed_dim=512, num_heads=6,\n","                 feed_forward_dim=2048, key_dim=64,\n","                 n_layers=8, \n","                 rate=0.1):\n","        super().__init__()\n","        self.layers_keys = ['layers_0', 'layers_1', 'layers_2', 'layers_3', 'layers_4', 'layers_5', 'layers_6', 'layers_7']\n","\n","        self.continuous_inputs_projection=layers.Dense(embed_dim, use_bias=False)\n","        self.pos_encoding = sinusoidal((n_frames, embed_dim))\n","        self.mt3_encoder_layers = keras.Sequential(\n","            [\n","                Mt3_Encoder_Layer(embed_dim=embed_dim, num_heads=num_heads,\n","                                   feed_forward_dim=feed_forward_dim, key_dim=key_dim,\n","                                   rate=rate)\n","                for _ in range(n_layers)\n","            ]\n","        )\n","        self.encoder_norm = layers.LayerNormalization(epsilon=1e-6, name='encoder_norm', scale=False)\n","\n","    def set_Encoder_weights_from_mt3(self, params):\n","\n","        continuous_inputs_projection_weights = params['continuous_inputs_projection']['kernel']\n","        self.continuous_inputs_projection.set_weights([continuous_inputs_projection_weights])\n","\n","        for ind, key in enumerate(self.layers_keys):\n","            layer_weigts = get_mt3_encoder_weights_to_Encoder_Norm_Attention_Norm(params[key])\n","            self.mt3_encoder_layers.layers[ind].set_norm_attention_norm_weights(layer_weigts)\n","            \n","    def freeze_copied_weights(self):\n","        self.continuous_inputs_projection.trainable=False\n","        for ind in range(len(self.layers_keys)):\n","            self.mt3_encoder_layers.layers[ind].freeze_norm_attention_norm()\n","\n","    def set_copied_weights_trainable(self):\n","        self.continuous_inputs_projection.trainable=True\n","        for ind in range(len(self.layers_keys)):\n","            self.mt3_encoder_layers.layers[ind].set_norm_attention_norm_trainable()\n","\n","\n","    def call(self, x):\n","        \n","        x = self.continuous_inputs_projection(x)\n","        x = x + self.pos_encoding[tf.newaxis, :tf.shape(x)[1], :]\n","        x = self.mt3_encoder_layers(x)\n","        x = self.encoder_norm(x)\n","\n","        return x\n","\n","\n","\n","\n","\n","\n","#@markdown EncoderLstm\n","\n","class EncoderLstm(keras.Model):\n","    def __init__(\n","        self,\n","        encoder, \n","        embed_dim=512,\n","        num_heads=6,\n","        feed_forward_dim=2048,\n","        key_dim=64,\n","        num_layers_enc=1,\n","        num_layers_dec=1,\n","        num_classes=2,\n","        batch_size=1,\n","        rate=0.0, \n","        GaussianNoise=0.0,\n","        n_lstm_units=512,\n","        use_fc_instead=False,\n","    ):\n","        super().__init__()\n","        self.batch_size=batch_size\n","        self.num_layers_dec=num_layers_dec\n","        self.embed_dim=embed_dim\n","        self.num_classes=num_classes\n","\n","        self.GaussianNoise_layer = tf.keras.layers.GaussianNoise(GaussianNoise)\n","        self.GaussianNoise = True if GaussianNoise>0 else False\n","\n","        self.encoder = encoder\n","\n","        self.use_fc_instead=use_fc_instead\n","        if use_fc_instead:\n","          self.decoder = layers.Dense(n_lstm_units, use_bias=False, activation='relu')\n","        else:\n","          self.decoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(n_lstm_units, return_sequences=True, return_state=True))\n","\n","        self.classifier = layers.Dense(num_classes, use_bias=False, activation='sigmoid')\n","\n","    def call(self, x):\n","\n","        if self.GaussianNoise:\n","            x = self.GaussianNoise_layer(x)\n","\n","        x = self.encoder(x)\n","\n","\n","        if self.use_fc_instead:\n","          y = self.decoder(x)\n","        else:\n","          y = self.decoder(x)[0]\n","\n","        return self.classifier(y)\n","\n"]},{"cell_type":"code","source":["#@markdown Transcriber utils\n","n_rounds = None\n","Discard_len = None\n","Samples = None\n","\n","DEBUG=True\n","def get_f0_pitches_from_frames(Frames_output, step_time=512/16000, threshold=0.5):\n","\n","    Frames_output_thr = np.where(Frames_output > threshold, Frames_output, 0)\n","    pitches=[]\n","    f0=[]\n","    for frame_i, frame in enumerate(Frames_output_thr):\n","        if np.sum(frame) > 0:\n","            pidx = np.argmax(frame)\n","\n","            pitch=pidx / 4\n","            if pitch%1==0.25 or pitch%1==0.75:\n","                pitch=round(pitch)\n","            elif pitch%1==0.5:\n","                if frame[pidx-1] < frame[pidx+1]:\n","                    pitch+=0.5\n","                else:\n","                    pitch-=0.5\n","                pitch=round(pitch)\n","\n","            if DEBUG:\n","                print(f'frame_i {frame_i} pidx {pidx} {(pidx / 4)%1} {frame[pidx-1]} {frame[pidx]} {frame[pidx+1]} pitch {pitch}')\n","\n","            f0.append([frame_i*step_time, midi_to_hz(pitch+MIN_MIDI)])\n","            pitches.append([frame_i*step_time, frame_i*step_time+step_time, int(pitch+MIN_MIDI)])\n","        else:\n","            f0.append([frame_i*step_time, 0])\n","            # pitches.append([frame_i*step_time, frame_i*step_time+step_time, 0])\n","\n","    return np.asarray(pitches), np.asarray(f0)\n","\n","def get_pitches_from_frames(Frames_output_thr, step_time=512/16000):\n","    pitches=[]\n","    for frame_i, frame in enumerate(Frames_output_thr):\n","        if np.sum(frame) > 0:\n","            pitches_indexes = np.where(frame==True)[0]\n","            for pitch in pitches_indexes:\n","              pitches.append([frame_i*step_time, frame_i*step_time+step_time, pitch])\n","    return np.asarray(pitches)\n","\n","def get_Values(n, Input_len, Overlap_len):\n","    # n = 3300\n","    # Input_len = 13\n","    # Overlap_len = 7\n","    global n_rounds\n","    global Discard_len\n","    global Samples\n","    Samples = np.arange(n)\n","\n","    Discard_len = Input_len - Overlap_len\n","\n","    n_rounds = int((n-Overlap_len)/Discard_len)\n","    Ratio = Input_len/Discard_len\n","    # print(n_rounds, Ratio)\n","\n","    Inputs = []\n","    for i in range(n_rounds):\n","        from_ = i*Discard_len\n","        to_ = from_ + Input_len\n","        input_ = Samples[from_:to_]\n","        Inputs.append(list(input_))\n","\n","    Inputs = np.array(Inputs)# first and last\n","    # print(Inputs.shape)\n","\n","    uni, counts = np.unique(Inputs, return_counts=True)\n","    importand_counts = counts[Overlap_len:-Overlap_len]\n","    cumsum_ = np.cumsum(importand_counts)\n","    index_ = list(cumsum_).index(Input_len) + 1\n","    assert (importand_counts[:index_]==importand_counts[index_:index_*2]).all()\n","    assert (importand_counts[:index_]==importand_counts[index_:index_*2]).any()\n","    # print(importand_counts[:index_],'\\n\\n')\n","\n","    # print(np.unique(importand_counts[:index_], return_counts=True), np.sum(importand_counts[:index_]),'\\n\\n')\n","\n","    for i in range(1, 5):\n","        check_ = i*Input_len\n","        index_check = list(cumsum_).index(check_)+1\n","        assert index_check/(index_)%1==0\n","        # print(index_check, index_check/(index_))\n","\n","    # print(counts[:Overlap_len])\n","    Values = 1/importand_counts[:index_]\n","    return Values\n","\n","def get_pitches_intervels_orff_output_for_onset_output(Frames, Accepted_Midis_Values, step_time, connect_ms_threshold=200):\n","\n","    connect_s_threshold = connect_ms_threshold/1000\n","    Pitches_dic = {}\n","\n","    for frame_i, frame in enumerate(Frames):\n","        for pitch_indx in np.where(frame>0)[0]:\n","            pitch = Accepted_Midis_Values[pitch_indx]\n","            if not pitch in Pitches_dic:\n","                Pitches_dic[pitch]=[]\n","            Pitches_dic[pitch].append(frame_i*step_time)\n","\n","    Pitches = []\n","    Intervels = []\n","\n","    for pitch in Pitches_dic:\n","        onsets = Pitches_dic[pitch]\n","        if len(onsets)>1:\n","            Intervel=[]\n","            last_onset = onsets[0]\n","            last_offset = last_onset+step_time\n","            for onset in onsets[1:]:\n","                if (onset - last_offset)<=connect_s_threshold:\n","                    last_offset = onset +  step_time\n","                else:\n","                    Pitches.append(pitch)\n","                    Intervels.append([last_onset, last_offset])\n","                    last_onset = onset\n","                    last_offset = last_onset + step_time\n","            Pitches.append(pitch)\n","            Intervels.append([last_onset, last_offset])\n","        else:\n","            Pitches.append(pitch)\n","            Intervels.append([onsets[0], onsets[0]+step_time])\n","\n","\n","    return Pitches, Intervels\n"],"metadata":{"cellView":"form","id":"BwJM0gj4v9y_","executionInfo":{"status":"ok","timestamp":1678629899980,"user_tz":-60,"elapsed":446,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@markdown Transcriber\n","\n","class Transcribe:\n","\n","    def __init__(self, model,\n","                 length_ms,\n","                 hop_sizes = [512],\n","                jumping_32mss = 5,\n","                thresholds = [0.5],\n","                connected_range_ms = 160,\n","                ONLY_FRAME=False,\n","                ONLY_ONSET=False,\n","                frequency_labels=False,\n","                connect_ms_threshold=0,\n","                 ):\n","        '''\n","        length_ms : length in milliseconds\n","        overlap from left and right in milliseconds\n","        connected_range_ms in milliseconds\n","        '''\n","        self.hop_sizes = hop_sizes\n","        self.length_ms = length_ms\n","        self.length_samples = int(self.length_ms * 0.001 * SAMPLE_RATE )\n","        self.jumping_samples = jumping_32mss * 512\n","\n","        self.thresholds = thresholds\n","        self.connected_range_ms = connected_range_ms\n","\n","        self.model = model\n","        self.model.sequence_length=self.length_samples\n","        self.model.batch_size=1\n","        self.MIDIs = []\n","        self.ONLY_FRAME=ONLY_FRAME\n","        self.ONLY_ONSET=ONLY_ONSET\n","        self.frequency_labels=frequency_labels\n","        self.connect_ms_threshold=connect_ms_threshold\n","\n","\n","    def Convert_output2Midi(self, MODEL_OUTPUT, hop_size):\n","\n","        if self.frequency_labels:\n","            Frames_output=np.zeros((MODEL_OUTPUT.shape[0], 88))\n","            index_c=-3\n","            weights=[0.0, 0.25, 0.75, 3., 0.75, 0.25, 0.0]\n","            weights=np.asarray(weights)/2\n","            weights=list(weights)\n","            for k in range(88):\n","                temp_indices=[]\n","                temp_weights=[]\n","                for w in range(7):\n","                    if index_c>=0 and index_c<88*7:\n","                        # print(\"w\", w, index_c, temp_indices)\n","                        temp_indices.append(index_c)\n","                        temp_weights.append(weights[w])\n","                    index_c+=1\n","                # index_c-=1\n","                index_c-=3\n","                # print(index_c, temp_indices)\n","                Frames_output[:,k]=(MODEL_OUTPUT[:,temp_indices]*temp_weights).sum(1)\n","\n","            for i, v in enumerate(Frames_output.max(1)):\n","                Frames_output[i]=(Frames_output[i]==v).astype(float)*v\n","        elif self.ONLY_FRAME or self.ONLY_ONSET:#TODO new\n","            Frames_output = MODEL_OUTPUT\n","        else :\n","            Onsets_output = MODEL_OUTPUT[:,:88]\n","            Frames_output = MODEL_OUTPUT[:,88:88*2]\n","            OFFSETS_output = MODEL_OUTPUT[:,88*2:]\n","\n","\n","        for threshold in self.thresholds:\n","            if self.ONLY_FRAME or self.ONLY_ONSET:#TODO new\n","                Frames_t = np.where(Frames_output>threshold, True, False)\n","                midi_path = self.midi_base_name+\"_\"+str(threshold)+\"_\"+str(hop_size)+\"_\"+str(self.length_ms)+\".mid\"\n","                DEFAULT_FRAMES_PER_SECOND = SAMPLE_RATE / hop_size\n","                sequence = sequences_lib.pianoroll_to_note_sequence(\n","                    Frames_t, frames_per_second=DEFAULT_FRAMES_PER_SECOND,\n","                        min_duration_ms=0, min_midi_pitch=0,  )\n","\n","            else :\n","                f_threshold = threshold/2\n","                Onsets_t = np.where(Onsets_output>threshold, Onsets_output, 0)\n","                Frames_t = np.where(Frames_output>f_threshold, True, False)\n","                OFFSETS_t = np.where(OFFSETS_output>threshold, OFFSETS_output, 0)\n","                midi_path = self.midi_base_name+\"_\"+str(threshold)+\"_\"+str(hop_size)+\"_\"+str(self.length_ms)+\".mid\"\n","                DEFAULT_FRAMES_PER_SECOND = SAMPLE_RATE / hop_size\n","                sequence = sequences_lib.pianoroll_to_note_sequence(\n","                    Frames_t,  onset_predictions=Onsets_t, offset_predictions=OFFSETS_t,\n","                    frames_per_second=DEFAULT_FRAMES_PER_SECOND, min_duration_ms=0, min_midi_pitch=0, )\n","\n","            print(\"For threshold {} -- Number of notes {}\".format(threshold, len(sequence.notes)))\n","\n","            midi_arr = np.zeros((len(sequence.notes), 3))\n","            for i in range(len(sequence.notes)):\n","                midi_arr[i][0] = sequence.notes[i].start_time + self.offset_time\n","                midi_arr[i][1] = sequence.notes[i].end_time + self.offset_time\n","                midi_arr[i][2] = sequence.notes[i].pitch+1\n","\n","\n","            try :\n","                # TODO save_midi\n","                save_midi(midi_path, midi_arr[:,2].astype(int)+MIN_MIDI-1, midi_arr[:,:2])\n","                self.MIDIs.append(midi_path)\n","                if self.ONLY_ONSET and False :\n","                    midi_arr_onsets = get_pitches_from_frames(Frames_t)\n","                    midi_path_2 = midi_path.replace('.mid', '_onsets.mid')\n","                    save_midi(midi_path_2, midi_arr_onsets[:,2].astype(int)+MIN_MIDI, midi_arr_onsets[:,:2])\n","                    self.MIDIs.append(midi_path_2)\n","            except :\n","                if len(midi_arr) == 0:\n","                    print(\"Empty\")\n","                else:\n","                    print(\"Error \")\n","                    print(midi_arr)\n","\n","        return sequence\n","\n","    def call(self, audio_path,\n","             audio_length=None,\n","             random_input_samples = None,\n","             midi_base_name = 'test', audio_from=None, audio_to=None):\n","        '''\n","        audio_length : length in milliseconds\n","        '''\n","        # TODO : length_samples must be a multiple of 512\n","        # TODO : audio and audio length must be a multiple of 512\n","        self.midi_base_name=midi_base_name\n","        audio, sr = librosa.load(audio_path, sr=SAMPLE_RATE)\n","        print(\"\\nAudio {} shape {} SampleRate {}\".format(audio_path, audio.shape, sr))\n","        if len(audio.shape) == 2:\n","            shape_len = len(audio.shape)\n","            audio = np.sum(audio, axis=1)/shape_len\n","\n","        self.offset_time = 0.0\n","        if audio_from or audio_to:\n","            # from_ = np.random.randint(audio.shape[0] - sequence_length)\n","            self.offset_time = audio_from\n","            audio = audio[int(audio_from*SAMPLE_RATE):int(audio_to*SAMPLE_RATE)]\n","        if random_input_samples :\n","            audio = np.random.random((random_input_samples))\n","        if audio_length :\n","            #TODO\n","            sequence_length = int(audio_length * 0.001 * SAMPLE_RATE )\n","            # from_ = np.random.randint(audio.shape[0] - sequence_length)\n","            audio = audio[:sequence_length]\n","\n","        # n_pad = self.jumping_samples - (audio.shape[0] - self.length_samples)%self.jumping_samples\n","        # if n_pad < self.jumping_samples :\n","        #     audio = np.pad(audio, (0, n_pad), 'constant')\n","\n","        for hop_size in self.hop_sizes :\n","            self.step_time=hop_size/16000\n","            length_bins = int(self.length_samples / hop_size)\n","            jumping_bins = int(self.jumping_samples / hop_size)\n","            mel_model=mel_tf_model\n","            tic_ = time.time()\n","            connected_range_bins = int((self.connected_range_ms * 0.001 * SAMPLE_RATE ) / hop_size)\n","            range__ = (audio.shape[0] - self.length_samples) //  self.jumping_samples + 1\n","            notes_threshold_dic = {}\n","            model_outputs = []\n","            if self.ONLY_FRAME  or self.ONLY_ONSET:\n","                MODEL_OUTPUT = np.zeros((int(self.length_samples/hop_size) + int(range__*(self.jumping_samples/hop_size)), 88))\n","            else :\n","                MODEL_OUTPUT = np.zeros((int(self.length_samples/hop_size) + int(range__*(self.jumping_samples/hop_size)), 264))\n","\n","            for i, from_i in enumerate(range(range__)):\n","                print(\"\\r\", from_i, '/', range__, end='')\n","                from_ = from_i * self.jumping_samples\n","                to_ = from_ + self.length_samples\n","                input_ = np.expand_dims(audio[from_:to_ - 1], 0)\n","                # print(\"input_\", input_.shape)\n","                mel_output = mel_model(input_)\n","                mel_output = tf.transpose(mel_output, perm=[0, 2, 1])\n","                # print(\"mel_output\", mel_output.shape)\n","\n","                # mel_output = tf.reshape(mel_output, [mel_output.shape[0], mel_output.shape[1], mel_output.shape[2]])#TODO\n","                # print(MODEL_OUTPUT.shape, mel_output.shape)\n","                model_output = self.model(mel_output).numpy()[0] # TODO : batch has to be 1 if more we need to loop\n","                # print(mel_output.shape)\n","\n","\n","                if i == 0 :\n","                    # print(MODEL_OUTPUT.shape, model_output.shape)\n","                    MODEL_OUTPUT[:ceil(self.length_samples/hop_size)] = model_output\n","                else :\n","                    temp_n_1 = ceil(self.length_samples/hop_size)\n","                    temp_n = ceil((self.jumping_samples/hop_size))\n","                    # print(temp_n_1, temp_n, self.jumping_samples)\n","                    MODEL_OUTPUT[temp_n*i:temp_n*(i-1)+temp_n_1] = (MODEL_OUTPUT[temp_n*i:temp_n*(i-1)+temp_n_1] + model_output[:-temp_n])/1\n","                    MODEL_OUTPUT[temp_n*(i-1)+temp_n_1:temp_n*(i)+temp_n_1] = model_output[-temp_n:]\n","\n","            Input_bins = self.length_samples/hop_size\n","            overlap_bins = Input_bins - self.jumping_samples/hop_size\n","            assert Input_bins%1==0\n","            assert overlap_bins%1==0\n","            Input_len=int(Input_bins)\n","            Overlap_len=int(overlap_bins)\n","            if Overlap_len>0 and Overlap_len<Input_len:\n","                Values = get_Values(n=Input_len*10, Input_len=Input_len, Overlap_len=Overlap_len)\n","                n_Values = Values.shape[0]\n","                indecies_values = (((np.arange(MODEL_OUTPUT.shape[0]) - Overlap_len) / n_Values) % 1 ) * n_Values\n","                # MODEL_OUTPUT[:-Input_len] *= Values[indecies_values.astype(int)][:-Input_len,np.newaxis]\n","                MODEL_OUTPUT *= Values[indecies_values.astype(int)][:,np.newaxis]\n","                print(f'Input_bins {Input_len} overlap_bins {Overlap_len} Values {Values}')\n","\n","            print(\"\\r\", end='')\n","            toc_ = time.time()\n","            Tran_time=toc_ - tic_\n","            print(\"Transcription Time:{} Inference time per-round:{}\".format(Tran_time, round((Tran_time/range__)*1000, 3) ))\n","            sequence = self.Convert_output2Midi(MODEL_OUTPUT, hop_size)\n","\n","\n","        return MODEL_OUTPUT, sequence, self.MIDIs\n"],"metadata":{"cellView":"form","id":"SAfOc1irnVz9","executionInfo":{"status":"ok","timestamp":1678629899981,"user_tz":-60,"elapsed":2,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#Choose model and load it"],"metadata":{"id":"LtosGBX0p365"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"um0aY7gNPXSw","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678629967632,"user_tz":-60,"elapsed":419,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}},"outputId":"85f78b56-2bfe-4be3-97f4-ace19b561907"},"outputs":[{"output_type":"stream","name":"stdout","text":["choice Piano 1 - Only Onset\n","0 Piano 1 - Only Onset\n","choice 0 urls 4\n","Model URL :    https://drive.google.com/drive/folders/1LxDf0mfpaTR5X4VwhXcwubRYx36VK2pP?usp=sharing\n","EncoderLstm_embed_dim_256_num_heads_6_feed_forward_dim_2048_num_layers_enc_8_key_dim_64_sequence_length_32768_HOP_LENGTH_512_lstmU_512__orgCho12__auc_87_130441\n"]}],"source":["#@markdown  Choose model\n","\n","\n","def update_model_params(folder_name):\n","    if folder_name.startswith('EncoderLstm'):\n","        global EncoderLstm_Model\n","        EncoderLstm_Model=True\n","        global ONLY_ONSET\n","        ONLY_ONSET =True\n","        for param in RNNTransformer_params:\n","            try:\n","                val = folder_name.split(param)[1]\n","                indx = val.find('_')\n","                try:\n","                    val = int(val[:indx])\n","                except:\n","                    val = val[:indx]\n","                exec(f'''global {param}\\n{param}={val}''')\n","            except:\n","                pass\n","\n","\n","urls = [\n","    'https://drive.google.com/drive/folders/1LxDf0mfpaTR5X4VwhXcwubRYx36VK2pP?usp=sharing',\n"," 'https://drive.google.com/drive/folders/1QrPmHU9HNb_OpAQSwZVExw26xa4tXHNj?usp=sharing',\n","   'https://drive.google.com/drive/folders/1vzk4DA0pQCXAx7pzdfrmPCTt88BAq5cI?usp=sharing',\n","     'https://drive.google.com/drive/folders/1hkoRwkOUItUe5swGMCRTq9bboIBHi5yP?usp=sharing',\n","]\n","\n","\n","Model_names = [\n","    'EncoderLstm_embed_dim_256_num_heads_6_feed_forward_dim_2048_num_layers_enc_8_key_dim_64_sequence_length_32768_HOP_LENGTH_512_lstmU_512__orgCho12__auc_87_130441',\n","    'EncoderLstm_embed_dim_256_num_heads_6_feed_forward_dim_2048_num_layers_enc_8_key_dim_64_sequence_length_16384_HOP_LENGTH_512_lstmU_512__OrgCho12Cent__auc_88_136149',\n","    'EncoderLstm_embed_dim_256_num_heads_6_feed_forward_dim_2048_num_layers_enc_8_key_dim_64_sequence_length_16384_HOP_LENGTH_512_lstmU_512_OrgCho12Aug__auc_85_142105',\n","    'EncoderLstm_embed_dim_500_num_heads_6_feed_forward_dim_2048_num_layers_enc_8_key_dim_64_sequence_length_16384_HOP_LENGTH_512_lstmU_512_OrgCho12Aug__auc_79_157789',\n","]\n","\n","choice = \"Piano 1 - Only Onset\" #@param ['Piano 1 - Only Onset', 'Piano 2 - Only Onset', 'Piano 3 - Only Onset', 'Piano 4 - Only Onset']\n","\n","\n","print(f'choice {choice}')\n","choices = ['Piano 1 - Only Onset', 'Piano 2 - Only Onset', 'Piano 3 - Only Onset', 'Piano 4 - Only Onset']\n","\n","choice = choices.index(choice)\n","\n","print(choice, choices[choice])\n","\n","print(f'choice {choice} urls {len(urls)}')\n","\n","url = urls[choice]\n","Model_Name = Model_names[choice]\n","if not os.path.isdir(Model_Name):\n","    !gdown --folder $url\n","\n","print(f'Model URL :    {url}')\n","\n","print(Model_Name)\n","Model_weights_path=Model_Name+'/keras_model'\n","\n","update_model_params(Model_Name)\n","\n"]},{"cell_type":"code","source":["#@markdown load model\n","\n","\n","\n","if EncoderLstm_Model==True:\n","    num_classes=88\n","    global ONLY_ONSET\n","    ONLY_ONSET=True\n","    embed_dim=embed_dim_\n","    num_heads=num_heads_\n","    feed_forward_dim=feed_forward_dim_\n","    key_dim=key_dim_\n","    num_layers_enc=num_layers_enc_\n","    num_classes=num_classes\n","    n_lstm_units=lstmU_\n","    mel_bins = embed_dim\n","    batch_size = 1\n","    \n","    sequence_length = 50*512\n","    n_frames = sequence_length//HOP_LENGTH\n","\n","    encoder=Mt3_Encoder(n_frames=200, \n","                            embed_dim=embed_dim, \n","                            num_heads=num_heads,\n","                            feed_forward_dim=feed_forward_dim,\n","                            n_layers=num_layers_enc,\n","                            key_dim=key_dim,\n","                            rate=0.0,\n","                            )\n","    \n","    try:\n","      encoder(np.ones((1, n_frames, mel_bins))).shape\n","    except:\n","      encoder(np.ones((1, n_frames, 256))).shape\n","\n","\n","    filters = get_forward_basis(window='hann', filter_length=WINDOW_LENGTH)\n","    mel_basis = get_mel_filter(n_mels=mel_bins, filter_length=WINDOW_LENGTH)\n","\n","    print(f'filters {filters.shape}')\n","\n","    EncoderFC = True if 'EncoderFC' in Model_weights_path else False\n","    model = EncoderLstm(\n","                encoder=encoder,\n","                batch_size=batch_size,\n","                embed_dim=embed_dim,\n","                num_heads=num_heads,\n","                feed_forward_dim=feed_forward_dim,\n","                key_dim=key_dim,\n","                num_layers_enc=num_layers_enc,\n","                num_classes=88,\n","                n_lstm_units=n_lstm_units,\n","                rate=0,\n","                GaussianNoise=0,\n","                use_fc_instead=EncoderFC\n","                )\n","\n","    dump_input=np.random.random((batch_size, int(sequence_length//HOP_LENGTH), mel_bins))\n","    print('output',  model(dump_input).shape)\n","\n","    model.load_weights(Model_weights_path)\n","    print(\"Layer one sum \", np.sum(model.weights[0]))\n","    # print(model.summary())\n","    model(dump_input).shape\n","\n","    print(f\"Model %s Is Ready\"%(Model_weights_path.split('/')[-2][-10:]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"r97dClGwr3NF","executionInfo":{"status":"ok","timestamp":1678630058676,"user_tz":-60,"elapsed":4420,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}},"outputId":"a0dd2709-9f68-4fc4-8232-7c1d7c93b357"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["filters (1, 2048, 1, 2050)\n","output (1, 50, 88)\n","Layer one sum  -14.900374\n","Model _87_130441 Is Ready\n"]}]},{"cell_type":"markdown","metadata":{"id":"LsWU4_fEw141"},"source":["#Transcribe Audios"]},{"cell_type":"code","execution_count":14,"metadata":{"cellView":"form","id":"OeYAkYgyBuL9","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1678630237475,"user_tz":-60,"elapsed":16078,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}},"outputId":"e539f4bd-58d9-4a4e-84f7-d727d68502b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-201b2114-2277-4dca-b8ec-2df12d34583e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-201b2114-2277-4dca-b8ec-2df12d34583e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 599-36-eval-1.wav to 599-36-eval-1.wav\n"]}],"source":["#@title Upload\n","uploaded = files.upload()\n","Files = []\n","for name in uploaded.keys():\n","    Files.append(name)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1678630237476,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"},"user_tz":-60},"id":"Lv934mHv7wjh","outputId":"e2f71caf-0a51-4895-9244-a6f0530cfd6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['599_36_fast.wav', '599-36-eval-1.wav']"]},"metadata":{},"execution_count":15}],"source":["Files=glob('*.wav')\n","Files"]},{"cell_type":"markdown","metadata":{"id":"mAybxOOW8EBm"},"source":["### Transcribe normally"]},{"cell_type":"code","execution_count":16,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1678630237476,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"},"user_tz":-60},"id":"NNJiKKbcRtyN","outputId":"da47076e-783b-43a3-8bb3-1aa0cfd910cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 256) [512] 16\n"]}],"source":["#@title Parameters\n","thresholds = [0.35, 0.25, 0.3, 0.1, 0.5]#@param\n","length_ms = 1024 # input to model in each iteration in milliseconds #@param\n","\n","hop_sizes= [HOP_LENGTH] #@ param\n","audio_from= None # starting second#@param\n","audio_to= None # ending second#@param\n","overlap_ms = 512 # value should be a multiple of 32 in milliseconds #@param\n","if overlap_ms >= length_ms:\n","    print(\"overlap_ms should be smaller than length_ms\")\n","    raise \"overlap_ms should be smaller than length_ms\"\n","\n","jumping_32mss= length_ms//32 - overlap_ms//32\n","\n","connect_ms_threshold=-1\n","mel_tf_model = mel_tf(filters,\n","                        mel_basis,\n","                        HOP_LENGTH)\n","  \n","dim2 = int(length_ms * 0.001 * SAMPLE_RATE )\n","dim2_ = ceil(dim2/HOP_LENGTH)\n","sinusoidal_t = tf.convert_to_tensor(sinusoidal((dim2_, mel_bins)))\n","\n","\n","print(sinusoidal_t.shape, hop_sizes, jumping_32mss)"]},{"cell_type":"code","execution_count":18,"metadata":{"cellView":"form","id":"gye7wnVkvCzj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678630272421,"user_tz":-60,"elapsed":4743,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}},"outputId":"776b8810-0d81-44a9-9537-409ab3400bea"},"outputs":[{"output_type":"stream","name":"stdout","text":[" 36 / 37Input_bins 32 overlap_bins 16 Values [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n","Transcription Time:11.060771226882935 Inference time per-round:298.94\n","For threshold 0.35 -- Number of notes 86\n","For threshold 0.25 -- Number of notes 132\n","For threshold 0.3 -- Number of notes 104\n","For threshold 0.1 -- Number of notes 605\n","For threshold 0.5 -- Number of notes 50\n","\n","Time:  25.832748353\n"]}],"source":["#@title Transcribe\n","\n","tic = time.process_time()\n","MIDIs = []\n","\n","for i_file, file_ in enumerate(Files) :\n","    print(\"\\nFile Number {} / {}\".format(i_file+1, len(Files)))\n","\n","    audio_path = file_\n","    Midi_to_test_path = ''\n","    Midi_base_name = Midi_to_test_path+audio_path.split('.')[0]\n","    Transcribe_model = Transcribe(model, length_ms=length_ms, hop_sizes= hop_sizes,\n","                            jumping_32mss=jumping_32mss, thresholds=thresholds,\n","                            ONLY_ONSET=ONLY_ONSET,\n","                                frequency_labels=False,\n","                                  connect_ms_threshold=connect_ms_threshold,\n","                                  )\n","\n","    MODEL_OUTPUT, sequence, t_MIDIs = Transcribe_model.call(audio_path=audio_path,\n","                                                        midi_base_name=Midi_base_name,\n","                                        audio_from=audio_from ,audio_to=audio_to)\n","    for i in t_MIDIs:\n","        MIDIs.append(i)\n","\n","    toc = time.process_time()\n","\n","print(\"\\nTime: \", toc - tic)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vbKMutrVLsF1"},"outputs":[],"source":["plot_midis_for_threshold='0.35'#@param\n","plot_sequences_midis_threhsold(MIDIs, threhsold_str=f'_{plot_midis_for_threshold}_')"]},{"cell_type":"code","source":["#@markdown listen to midi\n","convert_midi2wav_with_threshold='0.1'#@param\n","threhsold_str = f'_{convert_midi2wav_with_threshold}_'\n","for midi_ in MIDIs:\n","    if threhsold_str in midi_:\n","        midi2wav(midi_, midi_.replace('.mid', '.wav'), fs_path=fs_path)\n","        play_audio(midi_.replace('.mid', '.wav'))"],"metadata":{"cellView":"form","id":"F4ffVp53JiLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":75,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"id":"8FigVz_gvC16","outputId":"e2c1b409-70ef-4137-f3e8-3cb22420584a","executionInfo":{"status":"ok","timestamp":1678624136588,"user_tz":-60,"elapsed":254,"user":{"displayName":"Kareem 99","userId":"17052563737895329993"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_10615c9d-2f70-45e7-9085-9918cd151a6c\", \"MIDI_FILES.zip\", 37994)"]},"metadata":{}}],"source":["#@title Download MIDIs\n","from zipfile import ZipFile\n","\n","file_name = \"MIDI_FILES.zip\"\n","\n","with ZipFile(file_name,'w') as zip:\n","        for midi_ in MIDIs:\n","            zip.write(midi_)\n","\n","files.download(file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WhjcO8AEJ9JW"},"outputs":[],"source":["# !ffmpeg -i m.mp4 m.wav"]},{"cell_type":"code","source":[],"metadata":{"id":"Xfy8RIEHwMPi"},"execution_count":null,"outputs":[]}]}